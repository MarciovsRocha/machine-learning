{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "t13CRT0t3qTp"
   },
   "outputs": [],
   "source": [
    "# Definindo o valor das seeds para garantir reprodutibilidade\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Valor da seed a ser utulizada\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "# PYTHONHASHSEED environment variable\n",
    "os.environ['PYTHONHASHSEED']=str(RANDOM_SEED)\n",
    "\n",
    "# python built-in pseudo-random generator\n",
    "random.seed(RANDOM_SEED)\n",
    "\n",
    "# numpy\n",
    "np.random.seed(RANDOM_SEED)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XxjDrcRJYyA2"
   },
   "source": [
    "Neste exemplo treinamos e avaliamos um modelo preditivo usando **T-fold-CrossValidation**, ou Validação Cruzada com T Pastas\n",
    "\n",
    "- técnica de aprendizagem usada: Árvore de Regressão\n",
    "- tarefa supervisionada: regressão - valor diabetes\n",
    "- métricas de avaliação: coeficiente de determinação R2, mean_absolute_error\n",
    "\n",
    "Importando os recursos necessários:\n",
    "- numpy: biblioteca numérica\n",
    "- sklearn: biblioteca de machine learning, em especial a técnica Regression Tree, as métricas de avaliação e o model_selection que nos permite executar validação cruzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "SmS-tOd6u9fO"
   },
   "outputs": [],
   "source": [
    "# Importa bibliotecas necessárias \n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.datasets import load_diabetes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LuQLGeQNWpME"
   },
   "source": [
    "Carregando a base de dados do problema, representada aqui por X e y, onde:\n",
    "- X: array contendo N instâncias com M atributos (atributos de entrada do problema)\n",
    "- y: array contendo o valor do atributo alvo de cada instância em X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ypO-BKeSWlhU",
    "outputId": "65cff306-9899-41a4-fcbc-3f01f8ca511a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formato de X:  (442, 10)\n",
      "Formato de y:  (442,)\n"
     ]
    }
   ],
   "source": [
    "# Neste exemplo a base de dados diabetes é composta por 442 instâncias (N=442), \n",
    "# e cada instância é representada por um vetor de 10 atributos (M=10).\n",
    "\n",
    "X, y = load_diabetes(return_X_y=True)\n",
    "print(\"Formato de X: \", X.shape)\n",
    "print(\"Formato de y: \", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GoHd_-t7ddK8"
   },
   "source": [
    "Neste ponto definimos a técnica de Machine Learning a ser utilizada e treinamos o modelo usando Validação Cruzada. No exemplo, uma árvore de regressão. \n",
    "\n",
    "Observer que, diferente do HOLDOUT, não usamos a função *fit()* e sim *model_selection.cross_val_score()*. Esta função irá treinar T modelos. A cada iteração treina usando T-1 pastas e testa com uma delas. Troca a pasta de teste a cada iteração. Ao final fornece como resultado médio + desvio padrão.\n",
    "\n",
    "OBS: protocolo muito mais robusto que o HOLDOUT, pois cada instância do problema será teste em alguma iteração."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5sGXRIInYuUx",
    "outputId": "78d13369-6596-44df-c9ed-53a8341a5477"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tabulate'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m gs \u001b[38;5;241m=\u001b[39m GridSearchCV(model, parameters, scoring \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr2\u001b[39m\u001b[38;5;124m'\u001b[39m, cv\u001b[38;5;241m=\u001b[39mfolds, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m     18\u001b[0m gs\u001b[38;5;241m.\u001b[39mfit(X_val, y_val)\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtabulate\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tabulate\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m     22\u001b[0m df\u001b[38;5;241m=\u001b[39mgs\u001b[38;5;241m.\u001b[39mcv_results_\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tabulate'"
     ]
    }
   ],
   "source": [
    "# Treina do modelo com busca dos parâmetros via GridSearch\n",
    "# Definição dos parâmetros a serem avaliados \n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "\n",
    "parameters = [\n",
    "  {'max_depth': [3, 5, 10, 20], 'min_samples_split': [3, 5, 10], 'criterion':['absolute_error', 'squared_error'], 'splitter':['best', 'random']},\n",
    "  ]\n",
    "\n",
    "folds=5\n",
    "model = DecisionTreeRegressor()\n",
    "\n",
    "# separando uma parte para base de validação (20%)\n",
    "X, X_val, y, y_val = train_test_split(X, y, train_size=0.8, random_state=42)\n",
    "\n",
    "# GridSearch para customizar os parâmetros sobre base de validação\n",
    "gs = GridSearchCV(model, parameters, scoring = 'r2', cv=folds, n_jobs=5)\n",
    "gs.fit(X_val, y_val)\n",
    "\n",
    "from tabulate import tabulate\n",
    "import pandas as pd\n",
    "df=gs.cv_results_\n",
    "print(tabulate(df, headers='keys', tablefmt='psql'))\n",
    "print(\"Melhores parâmetros encontrados: \", gs.best_params_)\n",
    "\n",
    "# Definindo a técnica a ser utilizada\n",
    "model=gs.best_estimator_\n",
    "\n",
    "# Usando a validação cruzada com 5 folds neste exemplo.\n",
    "T=5 # número de pastas ou folds\n",
    "result = model_selection.cross_val_score(model, X, y, cv=T)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mJpnX6Ase_FW"
   },
   "source": [
    "Avaliação do modelo abaixo:\n",
    "\n",
    "- A variável *result* que criamos anteriormente tem o R2 calculado pelo *model_selection.cross_val_score()*.\n",
    "\n",
    "- A função *model_selection.cross_val_predict()* retorna o valor predito para cada exemplo de teste.\n",
    "\n",
    "- A função mean_absolute_error() retorna o erro médio absoluto calculado sobre a base de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_vN1HK85emfw",
    "outputId": "85fe54f7-d889-4505-86dd-88077cc57251"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Mostrando R2 médio e desvio padrão calculados na validação cruzada.\n",
    "print(\"\\nCross Validation Results %d folds:\" % T)\n",
    "print(\"R2 médio: %.5f\" % result.mean())\n",
    "print(\"Mean Std: %.5f\" % result.std())\n",
    "\n",
    "# Calculando o valor para cada exemplo de teste\n",
    "y_pred = model_selection.cross_val_predict(model, X, y, cv=T)\n",
    "\n",
    "# Exemplo mostrando o resultado previsto para a primeira instância de teste\n",
    "print(\"Primeira instância na base de teste apresenta valor diabetes: %d\" % y_pred[0])\n",
    "\n",
    "# Calculando o erro médio absoluto\n",
    "mae=mean_absolute_error(y, y_pred)\n",
    "print(\"Mean Absolute Error (MAE) calculado na base de teste: %.5f\" % mae)\n",
    "\n",
    "# salvando o modelo \n",
    "from joblib import dump, load\n",
    "with open(\"model.mod\", 'wb') as fo:  \n",
    "    dump(model, fo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KG_S1tMyC2J4"
   },
   "outputs": [],
   "source": [
    "# plotando a árvore após treinamento om a base toda\n",
    "from sklearn import tree\n",
    "reg = DecisionTreeRegressor()\n",
    "reg.fit(X,y)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import tree\n",
    "data=load_diabetes()\n",
    "\n",
    "_, ax = plt.subplots(figsize=(100,40))\n",
    "x=tree.plot_tree(reg, feature_names=data.feature_names, filled=True, ax=ax, fontsize=40)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 766
    },
    "id": "KNRPVfolZp2y",
    "outputId": "005b38de-60cd-4cd3-8824-dc1d87071b51"
   },
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(figsize=(100,40))\n",
    "x=tree.plot_tree(reg, feature_names=data.feature_names, filled=True, ax=ax, fontsize=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lMgRPNIMekfU"
   },
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "T_Fold_CrossValidation_TreeRegressor_GridSearch.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

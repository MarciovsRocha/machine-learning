{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cópia de FeatureExtraction_v05_06_2022.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-bfht2Sp04O"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0EHHune767p5"
      },
      "source": [
        "# Feature Extraction (Handcrafted and Deep Features)\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import math\n",
        "from skimage import feature\n",
        "from skimage.feature import hog\n",
        "from imutils import paths\n",
        "from google.colab.patches import cv2_imshow\n",
        "import os\n",
        "\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
        "from tensorflow.keras.applications.xception import Xception\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input\n",
        "\n",
        "# Load Inception_v3 pretrained on ImageNet dataset\n",
        "model = InceptionV3(include_top=False, weights='imagenet', pooling='avg', input_tensor=Input(shape=(299,299,3)))\n",
        "#model = Xception(include_top=False, weights='imagenet', pooling='avg')\n",
        "\n",
        "# List of paths \n",
        "import os\n",
        "file_list=[]\n",
        "file_list.append(os.listdir(r\"/content/drive/My Drive/Base1/humanos\"))\n",
        "file_list.append(os.listdir(r\"/content/drive/My Drive/Base1/praia\"))\n",
        "file_list.append(os.listdir(r\"/content/drive/My Drive/Base1/obras\"))\n",
        "file_list.append(os.listdir(r\"/content/drive/My Drive/Base1/onibus\"))\n",
        "file_list.append(os.listdir(r\"/content/drive/My Drive/Base1/dino\"))\n",
        "file_list.append(os.listdir(r\"/content/drive/My Drive/Base1/elefante\"))\n",
        "file_list.append(os.listdir(r\"/content/drive/My Drive/Base1/flores\"))\n",
        "file_list.append(os.listdir(r\"/content/drive/My Drive/Base1/cavalos\"))\n",
        "file_list.append(os.listdir(r\"/content/drive/My Drive/Base1/montanhas\"))\n",
        "file_list.append(os.listdir(r\"/content/drive/My Drive/Base1/comida\"))\n",
        "\n",
        "# general path\n",
        "path='/content/drive/My Drive/Base1/'\n",
        "\n",
        "# list of classes\n",
        "class_names=['humanos', 'praia', 'obras', 'onibus', 'dino', 'elefante', 'flores', 'cavalos', 'montanhas', 'comida'] \n",
        "#class_names=['dogs', 'cats']\n",
        "\n",
        "X_deep = []\n",
        "y = []\n",
        "\n",
        "# Feature extraction\n",
        "for classes_files, classe in zip (file_list, range(10)):\n",
        "    for i in range(100):\n",
        "      name= str(path) + str(class_names[classe]) + str('/') + str(classes_files[i]) \n",
        "      print(name)\n",
        "      y.append(classe)\n",
        "      \n",
        "# Extract deep features using InceptionV3 pretrained model \n",
        "      imagem = cv2.imread(name)\n",
        "      img = cv2.resize(imagem,(299,299))\n",
        "      xd = image.img_to_array(img)\n",
        "      xd = np.expand_dims(xd, axis=0)\n",
        "      xd = preprocess_input(xd)\n",
        "      deep_features = model.predict(xd)\n",
        "      print(deep_features.shape)\n",
        "      \n",
        "      X_image_aux = []\n",
        "      for aux in deep_features:\n",
        "          X_image_aux = np.append(X_image_aux, np.ravel(aux))\n",
        "    \n",
        "      deep_features = [i for i in X_image_aux]\n",
        "      \n",
        "      X_deep.append(deep_features)\n",
        "\n",
        "# Saving the extracted features (deep) in a csv file\n",
        "df = pd.DataFrame(X_deep)\n",
        "df.to_csv('X_deep.csv', header=False, index=False)\n",
        "\n",
        "# Saving the classes in a csv file\n",
        "df_class = pd.DataFrame(y)\n",
        "df_class.to_csv('y.csv', header=False, index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "0mnQt7HJUdqI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBXPtOFGX9Wd"
      },
      "source": [
        "# Example: how to load the csv files (features and labels)\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Labels\n",
        "y = pd.read_csv('y.csv', header=None)\n",
        "y=y.to_numpy()\n",
        "y=np.ravel(y)\n",
        "print(y.shape)\n",
        "\n",
        "# deep features\n",
        "X = pd.read_csv('X_deep.csv', header=None)\n",
        "X=X.to_numpy()\n",
        "print(X.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMXe_o54hCU_"
      },
      "source": [
        "# Treinamento de classificadores\n",
        "\n",
        "import numpy as np\n",
        "import urllib\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn import  model_selection\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# EXEMPLO USANDO HOLDOUT\n",
        "# Holdout -> dividindo a base em treinamento (60%) e teste (40%), estratificada\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=.4, random_state=42, stratify=y)\n",
        "\n",
        "# Treina o classificador\n",
        "\n",
        "clfa = GaussianNB()\n",
        "clfa = clfa.fit(X_train, y_train)\n",
        "\n",
        "# testa usando a base de testes\n",
        "predicted=clfa.predict(X_test)\n",
        "predp=clfa.predict_proba(X_test)\n",
        "\n",
        "# calcula a acurÃ¡cia na base de teste\n",
        "score=clfa.score(X_test, y_test)\n",
        "\n",
        "# calcula a matriz de confusÃ£o\n",
        "matrix = confusion_matrix(y_test, predicted)\n",
        "\n",
        "# apresenta os resultados\n",
        "print(\"Accuracy = %.2f \" % score)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(matrix)\n",
        "\n",
        "# EXEMPLO USANDO VALIDAÃ‡ÃƒO CRUZADA\n",
        "\n",
        "clfb = GaussianNB()\n",
        "\n",
        "folds=10\n",
        "result = model_selection.cross_val_score(clfb, X, y, cv=folds)\n",
        "print(\"\\nCross Validation Results %d folds:\" % folds)\n",
        "print(\"Mean Accuracy: %.2f\" % result.mean())\n",
        "print(\"Mean Std: %.2f\" % result.std())\n",
        "\n",
        "# matriz de confusÃ£o da validaÃ§Ã£o cruzada\n",
        "Z = model_selection.cross_val_predict(clfb, X, y, cv=folds)\n",
        "cm=confusion_matrix(y, Z)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IpqxNRkRgkvj"
      },
      "source": [
        "# Plot mistakes (images)\n",
        "print(predicted.shape)\n",
        "for i in range(len(predicted)):\n",
        "    if (predicted[i] != y_test[i]):\n",
        "        dist=1\n",
        "        j=0\n",
        "        while (j<len(X) and dist !=0): \n",
        "            dist = np.linalg.norm(X[j]-X_test[i])\n",
        "            j+=1\n",
        "        print(\"Label:\", y[j-1], class_names[y[j-1]], \"  /  Prediction: \", predicted[i], class_names[predicted[i]], predp[i][predicted[i]])\n",
        "        name= \"/content/drive/My Drive/Base1/\"+ str(class_names[y[j-1]]) + \"/\" + str(j)+ \".jpg\" \n",
        "        print(name)\n",
        "        im=cv2.imread(name)\n",
        "        cv2_imshow(im)\n",
        "        print(\"=============================================================================\")\n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
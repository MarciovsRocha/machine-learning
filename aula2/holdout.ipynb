{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XxjDrcRJYyA2"
   },
   "source": [
    "Neste exemplo treinamos e avaliamos um modelo preditivo usando **HOLDOUT**\n",
    "- técnica de aprendizagem usada: KNN (K-nearest Neighbors)\n",
    "- tarefa supervisionada: classificação de dígitos manuscritos\n",
    "- métricas de avaliação: taxa de acerto, precisão, revocação, f1 e matriz de confusão\n",
    "\n",
    "Importando os recursos necessários:\n",
    "- numpy: biblioteca numérica\n",
    "- sklearn: biblioteca de machine learning, em especial o KNN e as métricas de avaliação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "SmS-tOd6u9fO"
   },
   "outputs": [],
   "source": [
    "# Importa bibliotecas necessárias \n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "from sklearn.datasets import load_digits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LuQLGeQNWpME"
   },
   "source": [
    "Carregando a base de dados do problema, representada aqui por X e y, onde:\n",
    "- X: array contendo N instâncias com M atributos (atributos de entrada do problema)\n",
    "- y: array contendo o rótulo (atributo alvo) de cada instância de X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ypO-BKeSWlhU",
    "outputId": "e169e9b4-b521-434b-bf73-49d7ac8710eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formato de X:  (1797, 64)\n",
      "Formato de y:  (1797,)\n"
     ]
    }
   ],
   "source": [
    "# Neste exemplo a base de dados digits é composto por 1.797 instâncias (N=1.797), imagens de tamanho 8x8\n",
    "# e cada instância é representada por um vetor de 64 atributos (M=64), sendo que cada atributo pode ter um valor entre 0 e 16 (valor do pixel)\n",
    "\n",
    "X, y = load_digits(return_X_y=True)\n",
    "print(\"Formato de X: \", X.shape)\n",
    "print(\"Formato de y: \", y.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UtHXC-uRaros"
   },
   "source": [
    "Neste ponto definimos como faremos nosso HOLDOUT. Divide-se a base em uma porção para teste e o restante para treinamento. Neste exemplo, usamos 70/30, ou seja 70% para treinamento e 30% para teste.\n",
    "\n",
    "A função train_test_split faz isto de forma randômica e estratificada (respeitando a distribuição das classes), criando os seguintes arrays:\n",
    "\n",
    "- X_train e y_train: representam a base de treinamento\n",
    "- X_test e y_test: representam a base de teste\n",
    "\n",
    "Obs: \n",
    "- random_state é usado para garantir repetitibilidade dos experimentos\n",
    "- stratify é usada para que a divisão de treino e teste respeite a distribuição dos rótulos em y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "opt_bZeTcnD7"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JDezcCgLZ5d4",
    "outputId": "4361f2cf-8032-4a97-8c37-2793b7338f93"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formato de X_train:  (1257, 64)\n",
      "Formato de y_train:  (1257,)\n",
      "Formato de X_test:  (540, 64)\n",
      "Formato de y_test:  (540,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "print(\"Formato de X_train: \", X_train.shape)\n",
    "print(\"Formato de y_train: \", y_train.shape)\n",
    "print(\"Formato de X_test: \", X_test.shape)\n",
    "print(\"Formato de y_test: \", y_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GoHd_-t7ddK8"
   },
   "source": [
    "Neste ponto definimos a técnica de Machine Learning a ser utilizada e treinamos o modelo. No exemplo, um classificador KNN onde K=3. Importante destacar que há no sklearn outros parâmetros do KNN que podemos explorar na busca por um modelo robusto. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5sGXRIInYuUx",
    "outputId": "76104084-23de-47d0-90f1-ee51056c6a81"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=7)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definindo a técnica a ser utilizada\n",
    "clf = KNeighborsClassifier(n_neighbors=7,weights='uniform')\n",
    "\n",
    "# Treinando o modelo\n",
    "clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mJpnX6Ase_FW"
   },
   "source": [
    "A avaliação do modelo é realizada abaixo. \n",
    "\n",
    "- A função *predict()* retorna a classe para cada exemplo de teste.\n",
    "\n",
    "- A função *predict_proba()* retorna a probabilidade de cada classe para cada exemplo de teste.\n",
    "\n",
    "- A função *score()* retorna a taxa de acerto (acurácia) do classificador criado, observe que ela recebe como entrada a base de teste. A métrica taxa de acerto deve ser usada para bases balanceadas, no caso do problema apresentar diferença significativa na quantidade de exemplos por classe, deve-se usar *f1_score()* que é a média harmônica entre precisão e revocação.\n",
    "\n",
    "Considerando tp=true positivive, fp=false positive e fn=false negative.\n",
    "\n",
    "- A função *precision_score()*: calcula tp / (tp + fp)\n",
    "\n",
    "- A função *recall_score()* calcula: tp / (tp + fn)\n",
    "\n",
    "- A função *f1_score()* calcula a média harmônica entre precision e recall.\n",
    "\n",
    "- A função *confusion_matrix()* recebe como entrada os rótulos do teste (y_test) e a predição do modelo (y_pred). Ela retorna uma matriz CxC onde C é a quandidade de classes. No exemplo C=10, logo uma matriz 10x10 onde na diagonal temos os acertos e nas demais posições as confusões entre as classes do problema. Usada para avaliar classificador apenas e muito importante para analisarmos os erros do nosso modelo (ou hipótese de solução para o problema).  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_vN1HK85emfw",
    "outputId": "0070a875-2a33-45c2-d95a-dc4a52d320a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 98.333 \n",
      "Precision = 0.984 \n",
      "Recall = 0.983 \n",
      "F1 = 0.983 \n",
      "Primeira instância na base de teste foi considerada como da classe: 1\n",
      "Probabilidade de cada classe para a primeira instância:  [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Matriz de Confusão:\n",
      "[[53  0  0  0  1  0  0  0  0  0]\n",
      " [ 0 55  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 53  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 55  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 53  0  0  1  0  0]\n",
      " [ 0  0  0  0  0 54  0  0  0  1]\n",
      " [ 0  1  0  0  0  0 53  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 54  0  0]\n",
      " [ 0  2  0  1  0  0  0  1 48  0]\n",
      " [ 0  0  0  0  1  0  0  0  0 53]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Retorna a classe predita para cada exemplo de teste\n",
    "y_pred=clf.predict(X_test)\n",
    "\n",
    "# Retorna para cada instância de teste a probabilidade de cada classe\n",
    "predicted_proba=clf.predict_proba(X_test)\n",
    "\n",
    "# Calculando a acurácia (taxa de acerto) na base de teste (usando em bases balanceadas)\n",
    "score=clf.score(X_test, y_test)\n",
    "print(\"Accuracy = %.3f \" % (score*100))\n",
    "\n",
    "# Calculando a precisão na base de teste\n",
    "precision=precision_score(y_test, y_pred, average='weighted')\n",
    "print(\"Precision = %.3f \" % precision)\n",
    "\n",
    "# Calculando a revocação na base de teste\n",
    "recall=recall_score(y_test, y_pred, average='weighted')\n",
    "print(\"Recall = %.3f \" % recall)\n",
    "\n",
    "# Calculando a f1 na base de teste\n",
    "f1=f1_score(y_test, y_pred, average='weighted')\n",
    "print(\"F1 = %.3f \" % f1)\n",
    "\n",
    "# Exemplo mostrando o resultado previsto para a primeira instância de teste\n",
    "print(\"Primeira instância na base de teste foi considerada como da classe: %d\" % y_pred[0])\n",
    "\n",
    "# Exemplo abaixo mostrando para a primeira instância de teste a probabilidade de cada classe\n",
    "print(\"Probabilidade de cada classe para a primeira instância: \", predicted_proba[0])\n",
    "\n",
    "# Calculando a matriz de confusão\n",
    "print(\"Matriz de Confusão:\")\n",
    "matrix = confusion_matrix(y_test, y_pred)\n",
    "print(matrix)\n",
    "\n",
    "# salvando o modelo \n",
    "from joblib import dump, load\n",
    "with open(\"KNN.mod\", 'wb') as fo:  \n",
    "    dump(clf, fo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lMgRPNIMekfU"
   },
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Holdout.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
